{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1f9836-8396-4a79-aff3-ee3136ac5d15",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:29.266761Z",
     "iopub.status.busy": "2024-05-11T02:51:29.266374Z",
     "iopub.status.idle": "2024-05-11T02:51:29.270071Z",
     "shell.execute_reply": "2024-05-11T02:51:29.269505Z",
     "shell.execute_reply.started": "2024-05-11T02:51:29.266739Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModel, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31da14dc-618e-41e7-8f8b-998f9dce67e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:29.903602Z",
     "iopub.status.busy": "2024-05-11T02:51:29.903228Z",
     "iopub.status.idle": "2024-05-11T02:51:30.655860Z",
     "shell.execute_reply": "2024-05-11T02:51:30.655254Z",
     "shell.execute_reply.started": "2024-05-11T02:51:29.903581Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('tiansz/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e54646c-a789-4033-98af-c49e906c9b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:31.297023Z",
     "iopub.status.busy": "2024-05-11T02:51:31.296676Z",
     "iopub.status.idle": "2024-05-11T02:51:31.664103Z",
     "shell.execute_reply": "2024-05-11T02:51:31.663508Z",
     "shell.execute_reply.started": "2024-05-11T02:51:31.297005Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/workspace/.cache/modelscope/tiansz/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的BERT模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f9871b6-e1f4-4fc6-95c7-449933cf05fb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:32.947590Z",
     "iopub.status.busy": "2024-05-11T02:51:32.947247Z",
     "iopub.status.idle": "2024-05-11T02:51:32.952195Z",
     "shell.execute_reply": "2024-05-11T02:51:32.951632Z",
     "shell.execute_reply.started": "2024-05-11T02:51:32.947567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataframe.iloc[idx]['review']  # 使用标签索引\n",
    "        label = 1 if self.dataframe.iloc[idx]['label'] == 1 else 0  # 使用标签索引\n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5754efcb-1443-480e-af3a-86068e8946a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:35.907987Z",
     "iopub.status.busy": "2024-05-11T02:51:35.907645Z",
     "iopub.status.idle": "2024-05-11T02:51:35.938772Z",
     "shell.execute_reply": "2024-05-11T02:51:35.938122Z",
     "shell.execute_reply.started": "2024-05-11T02:51:35.907968Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    label, text = line.strip().split(\"\\t\")\n",
    "    data.append((int(label), text))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"label\", \"review\"])\n",
    "\n",
    "dataset = SentimentDataset(df, tokenizer, max_length=128)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8988a19-e17d-42a6-8c2b-25156a8603ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:37.675094Z",
     "iopub.status.busy": "2024-05-11T02:51:37.674727Z",
     "iopub.status.idle": "2024-05-11T02:51:37.753151Z",
     "shell.execute_reply": "2024-05-11T02:51:37.752651Z",
     "shell.execute_reply.started": "2024-05-11T02:51:37.675073Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置训练参数\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b4befc-06e0-42ba-8e30-d4d19e0a1d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T02:51:39.975178Z",
     "iopub.status.busy": "2024-05-11T02:51:39.974809Z",
     "iopub.status.idle": "2024-05-11T02:55:23.903317Z",
     "shell.execute_reply": "2024-05-11T02:55:23.902823Z",
     "shell.execute_reply.started": "2024-05-11T02:51:39.975156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1000/1000 [01:14<00:00, 13.51it/s]\n",
      "Epoch 2: 100%|██████████| 1000/1000 [01:14<00:00, 13.37it/s]\n",
      "Epoch 3: 100%|██████████| 1000/1000 [01:15<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in tqdm(train_loader, desc=\"Epoch {}\".format(epoch + 1)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae44cc77-7f8c-453a-bf72-931a0faee9f4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T03:11:00.102037Z",
     "iopub.status.busy": "2024-05-11T03:11:00.101701Z",
     "iopub.status.idle": "2024-05-11T03:11:06.116839Z",
     "shell.execute_reply": "2024-05-11T03:11:06.116284Z",
     "shell.execute_reply.started": "2024-05-11T03:11:00.102018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 250/250 [00:06<00:00, 41.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证集下评估模型\n",
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        accuracy = (preds == labels).float().mean()\n",
    "        total_eval_accuracy += accuracy.item()\n",
    "\n",
    "average_eval_accuracy = total_eval_accuracy / len(val_loader)\n",
    "print(\"Validation Accuracy:\", average_eval_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb271ef5-e975-4190-a336-9dcc382d429a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T03:26:56.106513Z",
     "iopub.status.busy": "2024-05-11T03:26:56.106163Z",
     "iopub.status.idle": "2024-05-11T03:26:56.119380Z",
     "shell.execute_reply": "2024-05-11T03:26:56.118787Z",
     "shell.execute_reply.started": "2024-05-11T03:26:56.106485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正面\n"
     ]
    }
   ],
   "source": [
    "# 使用微调后的模型进行预测\n",
    "def predict_sentiment(sentence):\n",
    "    inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    positive_prob = probs[0][1].item()  # 1表示正面\n",
    "    return positive_prob\n",
    "\n",
    "def predict(sentence):\n",
    "    positive_prob = predict_sentiment(sentence)\n",
    "    threshold = 0.5  # 设置阈值\n",
    "    if positive_prob > threshold:\n",
    "        print(\"正面\")\n",
    "    else:\n",
    "        print(\"负面\")\n",
    "\n",
    "predict(\"这家菜真好吃！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d61deaf2-ff6d-40ca-91b0-93e868413dd0",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-11T03:12:16.438503Z",
     "iopub.status.busy": "2024-05-11T03:12:16.438182Z",
     "iopub.status.idle": "2024-05-11T03:12:17.889158Z",
     "shell.execute_reply": "2024-05-11T03:12:17.888504Z",
     "shell.execute_reply.started": "2024-05-11T03:12:16.438477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 63/63 [00:01<00:00, 43.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9792857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义用于加载测试数据集的类\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length=128):\n",
    "        self.data = []\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                label, text = line.strip().split(\"\\t\")\n",
    "                self.data.append((int(label), text))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, text = self.data[idx]\n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 加载测试数据集\n",
    "test_dataset = TestDataset(\"test.txt\", tokenizer, max_length=128)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 评估模型\n",
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == labels).float().mean()\n",
    "    total_eval_accuracy += accuracy.item()\n",
    "\n",
    "average_eval_accuracy = total_eval_accuracy / len(test_loader)\n",
    "print(\"Test Accuracy:\", average_eval_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2690d",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant 数据准备\n",
    "    participant 模型微调\n",
    "    participant 模型评估\n",
    "    participant 代码实现\n",
    "    participant 自动生成测试数据\n",
    "\n",
    "    数据准备 -> 模型微调: 准备数据集\n",
    "    模型微调 -> 模型评估: 微调模型\n",
    "    模型评估 -> 代码实现: 评估模型性能\n",
    "    代码实现 -> 自动生成测试数据: 编写评估代码\n",
    "    自动生成测试数据 --> 代码实现: 生成测试数据\n",
    "    代码实现 -> 模型评估: 使用测试数据评估模型性能\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
